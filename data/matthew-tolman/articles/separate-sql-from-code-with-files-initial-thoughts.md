Recently I've been working on a side project that may or may not get published publicly
(I haven't decided yet). For this project, I decided I'd try a lot of new things, not all
of which worked out as well as I thought (which may be why it stays private). I've tried
a new Java/Kotlin framework, briefly tried a new JVM build system (and then went back to
Maven), tried new control flow mechanisms, new error handling techniques, etc. It's been
more of a playground for new ideas than a true product. I'm also treating the frontend the
same way by trying a lot of new technologies and ideas there as well.

One of the new ideas I've been trying is around managing SQL. A lot of frameworks use ORMs
to manage the interface between code and the database, which is sort of okay, but it has
always felt weird to me, especially once you get multiple data types involved in the same
request.

## SQL through ORMs

For instance, let's consider a site where users can log in and select different settings,
such as themes, fonts, etc. When a user creates an account, we want to set them up in
both the users table and setup default settings in the settings table. To do that with
an ORM, we would have code similar to the following.

```kotlin
// Imports are hidden for brevity

// src/main/kotlin/User.kt
@Dao
data class User (val email: String, @JsonIgnore val password: String)

// src/main/kotlin/UserSettings.kt
@Dao
data class UserSettings(
    val userId: Long,
    val theme: String,
    val font: String,
    // ... Any other settings go here
)

// src/main/kotlin/UserRepository.kt
class UserRespository extends Repository<User, Long> { /* Methods go here */ }

// src/main/kotlin/UserSettingsRepository.kt
class UserSettingsRespository extends Repository<UserSettings, Long> { /* Methods go here */ }

// src/main/kotlin/UserController.kt
@Controller
@RequestMapping("/users")
class UserController {
    @Autowired lateinit var userRepository: UserRepository
    @Autowired lateinit var userSettingsRepository: UserSettingsRepository

    @RequestMapping("/new")
    @ResponseBody
    fun createUser(params: NewUserReqest /* definition not shown for brevity) {
        NewUserValidator(params).assertIsValid() /* definition not shown for brevity */
        val id = userRepository.create(User(params.email, PasswordHasher.hash(params.password))
        // User is in the DB but not settings
        // A crash here could be bad
        userSettingsRepository.create(UserSettings(id, "light", "Consolas"))
    }
}

// src/main/kotlin/App.kt
@SpringBootApplication
class App {}

fun main(args: Array<String>) = SpringApplication.run(App::class, args)
```

There's a lot I don't like. First, there's a lot of unnecessary boilerplate. Not only
are we defining the objects we're working with, but we're also defining each repository
that we're using as well. So anytime I add a new table or data type, that's two more
classes that are being added. Additionally, anytime I want to use a table, I have to
autowire the specific repository for that table. That's a lot of friction for adding
to the DB.

There's another side effect too. Since my classes and my database are tightly coupled,
I can't change one without impacting the other. This means that optimization techniques,
such as normalizing or denormalizing the database, must be reflected in code. That
increases costs for changing dramatically.

We also have another side effect. Since we're using an ORM, we can no longer hire a DBA
to come in and just quickly optimize and profile our queries. All of our queries are
generated by the ORM, and that's it. If we wanted to optimize our queries, we'd have
to change the code, and even then we'd be limited by whatever ORM we chose.

Finally, there's one last piece that really annoys me. Whenever we have to work with
multiple related tables, we often have to make separate requests for each table. For
example, above we make one request to create the user entry, we then get the id for
the new user, and then we make a second request for the settings. Not only is this
slower (twice as many network requests), but it's a lot more dangerous, especially
if the ORM doesn't wrap the entire HTTP request in a transaction.

Assume that there isn't a transaction surrounding the request. This is fairly realistic,
especially with older systems or systems that have "custom" ORMs. When our program
crashes between the two requests (either due to faulty logic being introduced or
a network connection being lost), suddenly our database has corrupted data. We
intended for a user to always have a user settings entry, but in this case we don't.
If there's a single endpoint which assumes that our intended action is always the
case, then the user will break whenever they are ran through that code path. This could
result in weird settings or the user not being able to "log in" since the site crashes
as soon as it tries to load their profile.

If the HTTP request is in a transaction, the database will reset itself on a failure.
So everything's good, right?

Not quite. Even if there is a transaction, the system can get in a bad state. Imagine
that we had an email sending system, and we wanted to always send a welcome email
whenever a user is created. that could very easily happen in the user repository as
follows:

```kotlin
claass UserRespository extends Repository<User, Long> {
    @Autowired emailService: EmailService

    override fun create(user: User) {
        super.create(user)
        emailService.sendWelcomeTo(user.email)
    }
}
```

As a reminder, here is our user create code:

```kotlin
@RequestMapping("/new")
@ResponseBody
fun createUser(body: User /* definition not shown for brevity) {
    NewUserValidator(body).assertIsValid() /* definition not shown for brevity */
    val id = userRepository.create(User(body.email, PasswordHasher.hash(body.password))
    userSettingsRepository.create(UserSettings(id, "light", "Consolas"))
}
```

With the one little change in the user repository, the impact of a failure changes.
Even though the database realizes that the second request fails, the email system does
not know so a welcome email is still sent to the user. So the user doesn't get an account
but then does get an email saying they have an account. For a user, this is confusing
and will usually result in a call to support.

Now imagine that instead of simply sending an email, we processed a payment for a
service we offered. Now the user is without not only an account, but we've taken their
money without giving them what we promised.

## SQL through Views and Stored Procedures

One practice I've done in the past is to have the SQL I need be stored as stored
procedures and views. There are a few nice things to this approach. The first is that
we have separated our code and our SQL. This means that we no longer have to reflect
the logical SQL structure of tables into our code or vice versa. It also means that
DBAs can start looking at our queries and potentially optimize things a bit.

It also means that our code can now run more complex queries. For instance, instead
of having two requests to create our user and user settings, it could be done in
one request, as follows:


```kotlin
// DAOs are no longer needed, so we're excluding them in favor of maps until they are
// useful

// src/main/kotlin/UserController.kt
@Controller
@RequestMapping("/users")
class UserController {
    @RequestMapping("/new")
    @ResponseBody
    fun createUser(body: Map<String, *>, @Autowired dbConn: Connection) {
        NewUserValidator(body).assertIsValid() /* definition not shown for brevity */
        val pdo = dbConn.prepareStatement("EXEC newUser @email =?, @password = ?, @theme = ?, @font = ?")
        pdo.setString(1, body["email"] as String)
        pdo.setString(2, PasswordHasher.hash(body["password"] as String))
        pdo.setString(3, "light")
        pdo.setString(4, "Consolas")
        pdo.execute()
    }
}

// src/main/kotlin/App.kt
@SpringBootApplication
class App {}

fun main(args: Array<String>) = SpringApplication.run(App::class, args)

// newUser stored procedure
CREATE PROCEDURE newUser
    @email VARCHAR(255),
    @password VARCHAR(64),
    @theme VARCHAR(25),
    @font VARCHAR(32)
AS
BEGIN TRANSACTION
   DECLARE @ID int;
   INSERT INTO users (email, password) VALUES (@email, @password);
   SELECT @ID = scope_identity();
   INSERT INTO user_settings (user_id, font, theme) VALUES (@ID, @font, @theme);
COMMIT
GO
```

A few things to note. One is that we now have some SQL in the code, namely the command
to run a specific stored procedure. This isn't terrible as now we're only bound to the
stored procedure name and parameters. However, it does open up the door for a developer
to start using more and more custom SQL queries. This is especially problematic since
prepared statements are harder to manage than inline queries (more on this below), so
extra precautions will be needed to make sure that our inline SQL stays minimal.

The other thing to note is that we have prepared statements being used. It does make
things more verbose, but some verbosity is okay.

One nice thing is that we have gotten rid of four classes: User, UserSettings,
UserRepository, and UserSettingsRepository. None of those classes are needed anymore
since we can just use the built-in map type for the incoming data (and we can just use
the map type for any data returned directly to the user).

One of the downsides of this approach is that we now have to figure out how to manage
the stored procedure. Generally this is done through a database migration, but this now
means that any change to how we query the database (such as getting an additional
column in a SELECT statement) requires a migration. I'm not a huge fan of these
additional migrations since they add a lot of friction to the development pipeline,
especially in early stages of development when SELECTs and JOINs are in flux as teams
try to figure out what data is needed to accomplish the ( changing) feature requests.

Still, teams that already have a database migration system will find this system pretty
straightforward to implement.

## SQL as files

Now we get to the system that I've been experimenting with. It's similar to the stored
procedures with one main exception: queries are stored in resource files instead of the
database. The above code becomes the following:


```kotlin
// DAOs are no longer needed, so we're excluding them in favor of maps until they are
// useful

// src/main/kotlin/SqlLoader.kt
@Component
class SqlLoader {
    @Autowired var lateinit dbConn: Connection

    fun loadFile(sqlFile: String): PreparedStatement {
        // Load contents of SQL file from resources and return it
        // Caching can be added if needed
        let uri = Path.of(Objects.requireNonNull(Sql::class.java.classLoader.getResource(file)).toURI())

        // Creating prepared statement since this is an SQL script
        return dbConn.prepareStatement(Files.readString(uri))
    }
}

// src/main/kotlin/UserController.kt
@Controller
@RequestMapping("/users")
class UserController {
    @Autowired sqlLoader: SqlLoader

    @RequestMapping("/new")
    @ResponseBody
    fun createUser(body: Map<String, *>) {
        NewUserValidator(body).assertIsValid() /* definition not shown for brevity */
        val pdo = sqlLoader.loadFile("createUser.sql")
        pdo.setString(1, body["email"] as String)
        pdo.setString(2, PasswordHasher.hash(body["password"] as String))
        pdo.setString(3, "light")
        pdo.setString(4, "Consolas")
        pdo.execute()
    }
}

// src/main/kotlin/App.kt
@SpringBootApplication
class App {}

fun main(args: Array<String>) = SpringApplication.run(App::class, args)

// src/resources/createUser.sql
-- Note: could use variables to make it easier to know what's being substituted
DECLARE @ID int;
INSERT INTO users (email, password) VALUES (?, ?);
SELECT @ID = scope_identity();
INSERT INTO user_settings (user_id, font, theme) VALUES (@ID, ?, ?);
```

A few things to note about this example. First, it's longer than just using the prepared
statement since we now have a class to manage loading our scripts. However, that class
can be used for *all* of our queries. It's not a "one class per table" deal.

Second, we've removed all SQL from our code. While it's still possible for devs to start
introducing inline SQL, it's now less likely, especially since we're returning our
prepared statements from our SqlLoader instead of having devs create their own prepared
statements.

Furthermore, we've removed the need to manage prepared statements and views. Instead, we
now have SQL files that devs can easily change and iterate on. The separation of SQL like
this also comes with a nice advantage. A lot of SQL-based tools can now be used to write
and debug the queries without having to run the application code. This is especially
helpful for IDEs that have SQL tooling built in, like IntelliJ.

One thing that isn't as great is we now have a separation between how the substituted
parameters are declared and where they're used. If someone changes the query slightly,
then we could end up with code substituting in the wrong values, or vice versa.

We also now are referencing file names throughout our code. If a popular query gets
renamed, it would require lots of changes (prepared statements has the same problem too).

My solution was to have an enum of all possible queries and to have the enum maintain a
"mapping" between parameter names and their SQL type and position. For this, I defined
an enum class with all the queries and their parameters. Then, in my code instead of
specifying a file name, I specified an enum and passed in the values. I also set up my
SQL queries to use variables, that way the way data is used can be adjusted and moved
around without breaking the whole integration flow. Below is what my enum classes looked
like and how I used them (after adjusting my SQL loader class):

```kotlin
// src/main/kotlin/SqlQueries.kt
enum class SqlQueries(
val sqlFile: String,
val params: List<SqlParam> /* SqlParam maps JVM types to SQL types; ommitted for brevity */
) {
    NEW_USER(
            "create_user.sql",
            java.util.List.of(
                    SqlParam("email", String::class, 1),
                    SqlParam("password", String::class, 2),
                    SqlParam("font", String::class, 3),
                    SqlParam("theme", String::class, 4),
            )
    ),
    // ... rest of queries
    ;
}

// src/main/kotlin/UserController.kt
@Controller
@RequestMapping("/users")
class UserController {
    @Autowired sql: Sql /* Reworked class to also execute queries */

    @RequestMapping("/new")
    @ResponseBody
    fun createUser(body: Map<String, *>) {
        NewUserValidator(body).assertIsValid() /* definition not shown for brevity */
        sql.execute(SqlQueries.NEW_USER, mapOf(
            "email" to body["email"],
            "password" to PasswordHasher.hash(body["password"] as String),
            "theme" to "light",
            "font" to "Consolas"
        )
    }
}

// src/main/resources/create_user.sql
WITH
    variables (v_email, v_password, v_font, v_theme) as (
    VALUES (?, ?, ?, ?)
),
userInsert AS (
    INSERT INTO users ("password", email) SELECT v_password, v_email FROM variables
    RETURNING user_id
)
INSERT INTO user_settings (user_id, font, theme)
    SELECT user_id, v_font, v_theme FROM userInsert, variables;
```

Again, it's not perfect. There's still potential for SQL parameters to not get set
properly, but it's a lot closer than before, and it does shield a lot of the code from
changes. For instance, if we did change the order of our parameters, we'd only have to
adjust the query list, the rest of the code would stay the same. Likewise, if we removed
a parameter, we wouldn't have to change code since it would just ignore the extra keys in
the map.

Of course, there is the question of "why not use named parameters"? The answer is simply
that named parameters don't exist in JDBC. We'd have to pull in a library for that in
Java world.

That said, not all languages and libraries are limited to that. If we were in Node and
had named parameters, we could do something like the following:

```typescript
// sql.ts
export enum QUERIES {
    NEW_USER = "new_user.sql"
}

export async function runQuery(query: QUERIES, params: {[key: string] :any}): PreparedStatement {
    return await (new PreparedStatement(await fs.readFile(query))).execute(params)
}

// user_controller.ts
import {QUERIES, runQuery} from 'sql.ts'

export interface User {
    email: String,
    password?: String
}

export async function create_user(user: User) {
    await runQuery(QUERIES.NEW_USER, {
        "email": user.email,
        "password": hashPassword(user.password),
        "font": "Consolas",
        "theme": "light"
    })
}

// resources/create_user.sql
WITH userInsert AS (
    INSERT INTO users ("password", email) VALUES (:email, :password) RETURNING user_id
)
INSERT INTO user_settings (user_id, font, theme)
SELECT user_id, :font, :theme FROM userInsert;
```

The concept becomes a lot simpler with the right tooling available.

I am looking forward to playing around with the concept more. The idea hasn't been fully
tested yet. I do need to look at long-term maintainability, which will take time. At
some point, I'll need to see how it does with collaboration.

In theory, it should be pretty straightforward for a collaborative environment. All 
the queries are defined in enum types which can be discovered with autocomplete and
enforced with a compiler. However, theory does not always align with practice. For
instance, having to create a new enum for every SQL file could add enough friction
that the system starts to break down when scaled up. Or, perhaps having to write SQL
queries has more friction than creating boilerplate classes when scaled up.

The idea has promise, and I personally like it so far. We'll see how I still feel in a
year or two.
